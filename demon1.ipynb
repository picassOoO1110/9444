{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bb2e8-6483-459a-b15b-604e9d75049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.transforms import functional as F\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. 加载数据集\n",
    "dataset = load_dataset(\"ibrahimhamamci/DENTEX\", split=\"train\")  # 使用Huggingface上的DENTEX数据集\n",
    "\n",
    "# 2. 定义数据处理函数\n",
    "def preprocess_images(example):\n",
    "    image = example['image']  # 假设数据集中有'image'字段\n",
    "    boxes = example['boxes']  # 处理bounding box\n",
    "    labels = example['labels']  # 处理label (c)字段，异常牙齿的标签\n",
    "    image = F.to_tensor(image)\n",
    "    return image, {'boxes': torch.tensor(boxes), 'labels': torch.tensor(labels)}\n",
    "\n",
    "# 3. 数据预处理\n",
    "dataset = dataset.map(preprocess_images)\n",
    "\n",
    "# 4. 加载Faster R-CNN模型\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2  # 假设只有两类：正常牙齿和异常牙齿\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# 5. 训练模型\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# 定义优化器\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# 训练循环\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in dataset:  # 假设已经被DataLoader封装\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        # 前向传播\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {losses.item()}\")\n",
    "\n",
    "# 6. 保存模型\n",
    "torch.save(model.state_dict(), \"fasterrcnn_dental_model.pth\")\n",
    "\n",
    "# 7. 模型评估（可以基于AP, AR, F1等指标进行）\n",
    "# 此处可以加入代码进行测试集的评估。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7144e9-7193-4be5-a98d-4e4b32983665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdf1a4d-68dc-4aca-8256-55846c8c45b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.22-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (2.4.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in d:\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in d:\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.9-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
      "Requirement already satisfied: networkx in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Downloading ultralytics-8.3.22-py3-none-any.whl (877 kB)\n",
      "   ---------------------------------------- 0.0/877.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 877.5/877.5 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.9-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, ultralytics\n",
      "Successfully installed ultralytics-8.3.22 ultralytics-thop-2.0.9\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp39-cp39-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in d:\\anaconda3\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in d:\\anaconda3\\lib\\site-packages (from datasets) (3.10.5)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in d:\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "Downloading huggingface_hub-0.26.1-py3-none-any.whl (447 kB)\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pyarrow-17.0.0-cp39-cp39-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/25.1 MB 13.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.0/25.1 MB 12.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/25.1 MB 13.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 12.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 12.8/25.1 MB 12.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.5/25.1 MB 12.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.6/25.1 MB 12.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.2/25.1 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 11.7 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "Successfully installed datasets-3.0.2 huggingface-hub-0.26.1 multiprocess-0.70.16 pyarrow-17.0.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c6cef85-f030-4852-a196-25994ffe403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 3603\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 250\n",
      "    })\n",
      "})\n",
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=2955x1316 at 0x2084227ED60>}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载DENTEX数据集\n",
    "dataset = load_dataset(\"ibrahimhamamci/DENTEX\")\n",
    "\n",
    "# 查看数据集的结构和样本\n",
    "print(dataset)\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b175968-8527-4930-b867-87784aa5ff97",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'boxes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_50716\\2704034206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'boxes'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 假设每个样本有 'boxes' 字段，包含 bounding box 数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'labels'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 假设有类别标签 'labels'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'boxes'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 定义保存YOLO格式数据的目录\n",
    "train_dir = 'datasets/DENTEX/train'\n",
    "val_dir = 'datasets/DENTEX/val'\n",
    "\n",
    "# 创建YOLO格式的标签文件夹\n",
    "os.makedirs(f'{train_dir}/labels', exist_ok=True)\n",
    "os.makedirs(f'{val_dir}/labels', exist_ok=True)\n",
    "os.makedirs(f'{train_dir}/images', exist_ok=True)\n",
    "os.makedirs(f'{val_dir}/images', exist_ok=True)\n",
    "\n",
    "# 定义函数用于将bounding box转换为YOLO格式\n",
    "def convert_to_yolo_format(image_size, box):\n",
    "    x_center = (box[0] + box[2]) / 2.0 / image_size[0]\n",
    "    y_center = (box[1] + box[3]) / 2.0 / image_size[1]\n",
    "    width = (box[2] - box[0]) / image_size[0]\n",
    "    height = (box[3] - box[1]) / image_size[1]\n",
    "    return [x_center, y_center, width, height]\n",
    "\n",
    "# 处理训练集数据并生成YOLO格式的标签\n",
    "for i, example in enumerate(dataset['train']):\n",
    "    image = example['image']\n",
    "    boxes = example['boxes']  # 假设每个样本有 'boxes' 字段，包含 bounding box 数据\n",
    "    labels = example['labels']  # 假设有类别标签 'labels'\n",
    "    \n",
    "    # 保存图片\n",
    "    image_path = f'{train_dir}/images/{i}.jpg'\n",
    "    image.save(image_path)\n",
    "    \n",
    "    # 打开对应的标签文件\n",
    "    label_path = f'{train_dir}/labels/{i}.txt'\n",
    "    with open(label_path, 'w') as f:\n",
    "        for label, box in zip(labels, boxes):\n",
    "            yolo_box = convert_to_yolo_format(image.size, box)\n",
    "            # 将类别ID和转换后的box写入标签文件\n",
    "            f.write(f\"{label} {' '.join(map(str, yolo_box))}\\n\")\n",
    "\n",
    "print(\"训练集处理完成！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e163cec-2069-44d2-9429-c7e9c161792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': Image(mode=None, decode=True, id=None)}\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集中每个样本的字段\n",
    "print(dataset['train'].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4708de-10c5-42be-aebe-c6c9af4595ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 3603\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image'],\n",
      "        num_rows: 250\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 检查数据集的键和分片\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5324132c-9c58-4f83-8005-f14e5062f0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_50716\\234588953.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 假设dataset['train']中包含不同类型的标注\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 使用过滤条件筛选出类型(c)的数据 (这里需要根据实际字段进行调整)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mc_type_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"类型(c)数据量: {len(c_type_data)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_50716\\234588953.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 假设dataset['train']中包含不同类型的标注\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 使用过滤条件筛选出类型(c)的数据 (这里需要根据实际字段进行调整)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mc_type_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"类型(c)数据量: {len(c_type_data)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label_type'"
     ]
    }
   ],
   "source": [
    "# 假设你已经加载了DENTEX数据集\n",
    "# 只选择类型(c)的数据\n",
    "\n",
    "# 假设dataset['train']中包含不同类型的标注\n",
    "# 使用过滤条件筛选出类型(c)的数据 (这里需要根据实际字段进行调整)\n",
    "c_type_data = [example for example in dataset['train'] if example['label_type'] == 'c']\n",
    "\n",
    "print(f\"类型(c)数据量: {len(c_type_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4096235-2ed0-431d-ba85-cb8c2c5ea08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=2955x1316 at 0x20842575130>}\n"
     ]
    }
   ],
   "source": [
    "# 查看第一个样本的完整内容，看看是否有其他字段存储类型信息\n",
    "print(dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf112b-6d8c-4434-ac04-fee12042487b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
